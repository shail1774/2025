az group create --name TerraformStateRG --location

az storage account create --name tfstateaccount082025 --resource-group TerraformStateRG --location centralindia --sku Standard_LRS



az storage container create --account-name tfstateaccount082025 --name terraform-state --auth-mode login


terraform init

terraform init
terraform validate
terraform plan
terraform apply
terraform destroy



Fluxcd


flux bootstrap git  --token-auth=true  --url=https://dev.azure.com/techrock2025/test_2025/_git/FluxCDrepo  --branch=flux-cd-1  --username=git  --password="$GIT_PASSWORD"  --path=clusters/aks-dummy







PS C:\Test_2025\fluxcd> flux bootstrap git  --token-auth=true  --url=https://dev.azure.com/techrock2025/test_2025/_git/FluxCDrepo  --branch=flux-cd-1  --username=git  --password="$GIT_PASSWORD"  --path=clusters/aks-dummy
Please enter your Git repository password: 
► cloning branch "flux-cd-1" from Git repository "https://dev.azure.com/techrock2025/test_2025/_git/FluxCDrepo"
✔ cloned repository
► generating component manifests
✔ generated component manifests
✔ committed component manifests to "flux-cd-1" ("f5d028ca3e69873ef2b782543205d2ab7b13546a")
► pushing component manifests to "https://dev.azure.com/techrock2025/test_2025/_git/FluxCDrepo"
► installing components in "flux-system" namespace
✔ installed components
✔ reconciled components
► determining if source secret "flux-system/flux-system" exists
► generating source secret
► applying source secret "flux-system/flux-system"
✔ reconciled source secret
► generating sync manifests
✔ generated sync manifests
✔ committed sync manifests to "flux-cd-1" ("89df9344128c2ddcccd65653a60499221f4b00f8")
► pushing sync manifests to "https://dev.azure.com/techrock2025/test_2025/_git/FluxCDrepo"
► applying sync manifests
✔ reconciled sync configuration
◎ waiting for GitRepository "flux-system/flux-system" to be reconciled
✔ GitRepository reconciled successfully
◎ waiting for Kustomization "flux-system/flux-system" to be reconciled
✔ Kustomization reconciled successfully
► confirming components are healthy
✔ helm-controller: deployment ready
✔ kustomize-controller: deployment ready
✔ notification-controller: deployment ready
✔ source-controller: deployment ready
✔ all components are healthy


 
 Check Flux reconciliation status 
kubectl get pods -n  kube-system
flux get kustomizations -n kube-system
flux get helmreleases -n kube-system

flux reconcile helmrelease ingress-nginx -n kube-system
flux get helmreleases -n  kube-system

Inspect event logs for cert-manager resources

kubectl get events -n kube-system --sort-by='.metadata.creationTimestamp'


kubectl describe helmrelease cert-manager -n kube-system

Validate CustomResourceDefinitions (CRDs)
kubectl get crds | grep cert-manager

If CRDs are missing, cert-manager pods won’t start.

Flux HelmRelease should be configured with install.crds: Create to install CRDs automatically.


Confirm Flux components are healthy
kubectl get pods -n flux-system


To configure cert-manager to issue certificates for your applications running on your Kubernetes cluster, 
you need to create an Issuer or a ClusterIssuer resource that represents the certificate authority (CA) cert-manager will use to sign certificates. Then you create Certificate resources to request certificates for your apps.


helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm search repo ingress-nginx/ingress-nginx --versions


1. Suspend and Resume the HelmRelease
This forces the Helm controller to reset and retry reconciliation:

bash
flux suspend helmrelease ingress-nginx -n kube-system
flux resume helmrelease ingress-nginx -n kube-system

2. Annotate the HelmRelease to reset retries
You can reset Helm controller retry counts by adding a timestamp annotation:

bash
flux annotate helmrelease ingress-nginx -n kube-system reconcile.fluxcd.io/resetAt="$(date +%s)" --overwrite
flux reconcile helmrelease ingress-nginx -n kube-system
This triggers Flux to retry the Helm release operations.

3. Check HelmRelease status and events
Use kubectl describe to see error details or failure reasons:

bash
kubectl describe helmrelease ingress-nginx -n kube-system
kubectl get events -n kube-system --sort-by='.metadata.creationTimestamp'

4. Check Helm release status manually
Verify the Helm release state with Helm CLI:

bash
helm status ingress-nginx -n kube-system

If it is stuck, you may need to manually intervene (e.g., rollback or uninstall via Helm).

5. Delete HelmRelease Secret locks if stuck
Sometimes a HelmRelease may stuck due to stale secret locks. List and delete Helm secrets related to the release:

bash
kubectl get secrets -n kube-system | grep ingress-nginx
kubectl delete secret <secret-name> -n kube-system
Be cautious as deleting Helm secrets affects release tracking.

6. Check Flux and Helm controller logs
Look at the Helm controller logs to identify detailed errors:

bash
kubectl logs -n flux-system deployment/helm-controller

7. Increase HelmRelease install/upgrade timeouts
In your HelmRelease YAML, you can set:

text
spec:
 install:
   timeout: 15m0s
 upgrade:
   timeout: 15m0s
To allow more time for Helm operations on large charts.

8. Force reconciliation again
Finally, try a force reconcile with reset flag:

bash
flux reconcile helmrelease ingress-nginx -n kube-system --reset
If issues persist, sharing HelmRelease YAML and controller logs would help diagnose more specifically.

1. Check the status of all Flux resources in all namespaces:
bash
flux get all --all-namespaces

echo "$(pwd)/clusters/aks-main/Ado-Agent"
kustomize build ./clusters/aks-main/Ado-Agent

kubectl scale deploy ado-agent --replicas=0 -n kube-system


Flux Kustomization Health
You can check the health of all Kustomizations:

bash
kubectl get kustomizations -A
